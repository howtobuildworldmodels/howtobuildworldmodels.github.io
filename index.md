---
title: Home
layout: page
---

# Tutorial on Generative Models for Content Creation, Reconstruction, and Beyond

Tutorial will take place at [Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP) 2025](https://icvgip.in/2025/) organised by IIT Mandi from Dec 17-20.

## Overview ðŸš€

**Abstract**
Generative models have advanced rapidly in recent years, driving breakthroughs across image and video synthesis, 3D scene understanding, and even text generation. Among these, diffusion models have emerged as one of the most powerful and versatile generative frameworks. This tutorial provides a comprehensive introduction to diffusion models, covering their core principles, key design choices, and the evolution of architectures enabling state-of-the-art performance in modern computer vision tasks. We begin with foundational concepts and gradually build toward advanced topics, ensuring accessibility for newcomers while offering depth for experienced researchers. The tutorial is organized into three sections as outlined below:

### [Section 1] Introduction to Diffusion Models and their application in Content Creation

### Index

- **What are Diffusion Model?**
  - Conditional Generation
  - Classifier Guidance
- **Latent Diffusion Models**
  - Conditional generation with ControlNet
- **Image Editing via Attention Manipulation**
  - Prompt2Prompt
- **Image Composition with Diffusion Models**
  - DAEdit
- **Personalization in Diffusion Models**
  - PreciseControl
  - Text2Place
- **Diffusion Image Transformers (DiT)**
  - SeeThrough3D
- **Instruction-based Image Editing**
  - InstructPix2Pix
  - Flux Kontext




### [Section 2] Diffusion Models for 3D Reconstruction and Scene Understanding
### [Section 3] Diffusion Models for Video Generation and Multimodal Applications

## Speakers
<span style="color: red;">Rishubh Parihar</span>

<span style="color: red;">Ankit Dhiman</span>

<span style="color: red;">Badrinath Singhal</span> 


## Prerequisites
To get the most out of sessions, attendees should be comfortable with:
Deep Learning Fundamentals: Working knowledge of CNNs, RNNs/Transformers, and loss functions.
Python & PyTorch/TensorFlow: Ability to read and modify deep learning code.



## Organisers
1. Ankit Dhiman (PhD Student at [Vision and AI Lab (VAL)](https://val.cds.iisc.ac.in/index.html) at IISc, Bangalore)
2. Badrinath Singhal (PhD Student at [Vision and AI Lab (VAL)](https://val.cds.iisc.ac.in/index.html) at IISc, Bangalore)
3. AS Anudeep (Masters Student at IISc, Bangalore)
4. Rishubh Parihar (PhD Student at [Vision and AI Lab (VAL)](https://val.cds.iisc.ac.in/index.html) at IISc, Bangalore)

   
**Questions**: For any inquiries regarding the tutorial content, please contact us at [badrinaths@iisc.ac.in](badrinaths@iisc.ac.in) with subject of the email as "Tutorial at ICVGIP 2025".

------

[Credits for the website](https://github.com/evanwill/workshop-template-b)
